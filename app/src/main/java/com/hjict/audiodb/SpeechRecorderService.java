package com.hjict.audiodb;

import android.app.Notification;
import android.app.NotificationChannel;
import android.app.NotificationManager;
import android.app.Service;
import android.content.Intent;
import android.media.AudioFormat;
import android.media.AudioRecord;
import android.media.MediaRecorder;
import android.os.Build;
import android.os.IBinder;
import android.util.Log;

import androidx.core.app.NotificationCompat;

import com.hjict.audiodb.Utils;

import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import java.text.SimpleDateFormat;
import java.util.Date;
public class SpeechRecorderService extends Service {
    private AudioRecord recorder;
    private boolean isRunning = false;
    private VadWrapper vad;
    private ByteArrayOutputStream speechBuffer;

    private CircularAudioBuffer preBuffer;
    private long lastSpeechTime = 0;
    private static final int SAMPLE_RATE = 16000;
    private static final int FRAME_SIZE = 160; // 10ms @ 16kHz
    private static final int SILENCE_TIMEOUT_MS = 2000;

    private boolean isRecording = false;
    private int silenceFrameCount = 0;
    private int speechFrameCount = 0;
    private final int MIN_SPEECH_FRAMES = 100;  // ì˜ˆ: 100 frames = 1ì´ˆ (10ms * 100)
    private final int MAX_SILENCE_FRAMES = 100; // ì˜ˆ: 200 frames = 2ì´ˆ (10ms * 200)

    @Override
    public int onStartCommand(Intent intent, int flags, int startId) {
        // Foreground ì„œë¹„ìŠ¤ìš© ì•Œë¦¼ ìƒì„±
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
            NotificationChannel channel = new NotificationChannel(
                    "speech_channel",
                    "Speech Recorder",
                    NotificationManager.IMPORTANCE_LOW
            );
            NotificationManager manager = getSystemService(NotificationManager.class);
            if (manager != null) {
                manager.createNotificationChannel(channel);
            }
        }

        Notification notification = new NotificationCompat.Builder(this, "speech_channel")
                .setContentTitle("ìŒì„± ê°ì§€ ì¤‘")
                .setContentText("ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤...")
                .setSmallIcon(R.drawable.ic_launcher_background)  // ì ì ˆí•œ ì•„ì´ì½˜ ì„¤ì • í•„ìš”
                .build();

        startForeground(1, notification); // í•„ìˆ˜ í˜¸ì¶œ

        // 3ì´ˆ = 300 í”„ë ˆì„ (10ms), í”„ë ˆì„ë‹¹ 160 samples * 2 bytes = 320 bytes
        int frameSize = FRAME_SIZE * 2;
        preBuffer = new CircularAudioBuffer(300, frameSize); // 300ê°œ í”„ë ˆì„ ë³´ê´€ìš©

        // ë‚˜ë¨¸ì§€ ë¡œì§
        vad = new VadWrapper();
        vad.init(3); //  ë¯¼ê°
        new Thread(this::recordLoop).start();
        return START_STICKY;
    }

    private void recordLoop() {
        int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE,
                AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT);

        recorder = new AudioRecord(MediaRecorder.AudioSource.MIC,
                SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO,
                AudioFormat.ENCODING_PCM_16BIT, bufferSize);

        recorder.startRecording();
        isRunning = true;

        final int FRAME_SIZE = 160; // 10ms @ 16kHz
        final long MAX_RECORDING_MS = 5000;
        final long MIN_RECORDING_MS = 3000;
        final long SILENCE_TIMEOUT_MS = 1000;

        long recordingStartTime = 0;
        long lastSpeechTime = 0;
        boolean isRecording = false;

        speechBuffer = new ByteArrayOutputStream();
        CircularAudioBuffer preBuffer = new CircularAudioBuffer(300, FRAME_SIZE * 2);
        List<byte[]> fftWindow = new ArrayList<>();

        byte[] buffer = new byte[FRAME_SIZE * 2];

        while (isRunning) {
            int read = recorder.read(buffer, 0, buffer.length);
            if (read != buffer.length) continue;

            preBuffer.addChunk(buffer);
            fftWindow.add(buffer.clone());
            if (fftWindow.size() > 3) fftWindow.remove(0);  // 50ms sliding window

            double db = Utils.calculateDb(buffer, read);
            boolean isSpeech = vad.isSpeech(buffer, SAMPLE_RATE);
            boolean isVoiceFreq = false;

            if (fftWindow.size() == 3) {
                byte[] fftInput = mergeFrames(fftWindow);
                isVoiceFreq = FftUtils.isHumanVoice(fftInput, SAMPLE_RATE);
            }

            long now = System.currentTimeMillis();
            if (isSpeech){
                if (db > -30 && isVoiceFreq) {
                    Log.i("limdb","db:"+(int)db+"  isSpeech:"+isSpeech+"  Freg:"+ isVoiceFreq);
                } else {
//                    Log.e("limdb","db:"+(int)db+"  isSpeech:"+isSpeech+"  Freg:"+ isVoiceFreq);
                }
            }else{
//                Log.e("limdb","db:"+(int)db+" isSpeech:"+isSpeech+"  Freg:"+ isVoiceFreq);

            }
            if (db > -30 && isSpeech && isVoiceFreq) {
                if (!isRecording) {
                    isRecording = true;
                    recordingStartTime = now;
                    speechBuffer.reset();
                    Log.i("Recorder", "â–¶ ë…¹ìŒ ì‹œì‘");
                }

                try {
                    speechBuffer.write(buffer);
                    lastSpeechTime = now;
                } catch (IOException e) {
                    Log.e("Recorder", "ë²„í¼ ì“°ê¸° ì‹¤íŒ¨", e);
                }
            } else if (isRecording) {
                long duration = now - recordingStartTime;
                long silenceDuration = now - lastSpeechTime;

                if (silenceDuration > SILENCE_TIMEOUT_MS && duration >= MIN_RECORDING_MS) {
                    saveWavFile(speechBuffer.toByteArray());

//                    finalizeAndSave(preBuffer, speechBuffer, duration, MAX_RECORDING_MS);
                    isRecording = false;
                } else if (silenceDuration > SILENCE_TIMEOUT_MS) {
                    isRecording = false;
                    Log.i("Recorder", "â–  ë…¹ìŒ ì·¨ì†Œ (ì§§ìŒ)");
                } else if (duration >= MAX_RECORDING_MS) {
                    saveWavFile(speechBuffer.toByteArray());
                    isRecording = false;
                    Log.i("Recorder", "â–  ë…¹ìŒ ê°•ì œì¢…ë£Œ (5ì´ˆ ì´ˆê³¼)");
                }
            }
        }

        recorder.stop();
        recorder.release();
    }


//    private void recordLoop() {
//        int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE,
//                AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT);
//
//        recorder = new AudioRecord(MediaRecorder.AudioSource.MIC,
//                SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO,
//                AudioFormat.ENCODING_PCM_16BIT, bufferSize);
//
//        recorder.startRecording();
//        isRunning = true;
//
//        speechBuffer = new ByteArrayOutputStream();
//        byte[] buffer = new byte[FRAME_SIZE * 2];
//
//// ì„¤ì •ê°’: ìµœì†Œ/ìµœëŒ€ ë…¹ìŒ ì‹œê°„, ë¬´ìŒ ì§€ì† ì‹œê°„
//        final long MAX_RECORDING_MS = 5000;       // ìµœëŒ€ 5ì´ˆ ë…¹ìŒ
//        final long MIN_RECORDING_MS = 3000;       // ìµœì†Œ 2ì´ˆ ì´ìƒì¼ ë•Œë§Œ ì €ì¥ (2ì´ˆ + ë¬´ìŒ ê°ì§€ 2ì´ˆ)
//        final long SILENCE_TIMEOUT_MS = 2000;     // 2ì´ˆ ì´ìƒ ë¬´ìŒì´ë©´ ë§ì´ ëë‚¬ë‹¤ê³  íŒë‹¨
//
//// íƒ€ì´ë¨¸ ì´ˆê¸°í™”
//        long recordingStartTime = 0;              // ë…¹ìŒ ì‹œì‘ ì‹œê°„ ê¸°ë¡ìš©
//        long lastSpeechTime = 0;                  // ë§ˆì§€ë§‰ìœ¼ë¡œ ë§ì†Œë¦¬ ê°ì§€ëœ ì‹œì 
//        boolean isRecording = false;              // í˜„ì¬ ë…¹ìŒ ì¤‘ì¸ì§€ ì—¬ë¶€
//
//        while (isRunning) {
//            // AudioRecordë¡œ ì˜¤ë””ì˜¤ í”„ë ˆì„ ì½ê¸° (10ms ë‹¨ìœ„)
//            int read = recorder.read(buffer, 0, buffer.length);
//            if (read != buffer.length) continue;  // ì½ê¸° ì‹¤íŒ¨ ë˜ëŠ” ë¶ˆì™„ì „í•œ í”„ë ˆì„ì€ ê±´ë„ˆëœ€
//
//            // í”„ë¦¬ë²„í¼ì— í•­ìƒ ìŒ“ê¸° (10ms ë‹¨ìœ„ í”„ë ˆì„)
//            preBuffer.addChunk(buffer);
//
//            // í˜„ì¬ í”„ë ˆì„ì˜ ë°ì‹œë²¨ ê³„ì‚°
//            double db = Utils.calculateDb(buffer, read);
//
//            // í˜„ì¬ í”„ë ˆì„ì˜ ì£¼íŒŒìˆ˜ê°€ ì‚¬ëŒ ëª©ì†Œë¦¬ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ”ì§€ ê²€ì‚¬ (ex: 300~3000Hz)
//            boolean isVoiceFreq = FftUtils.isHumanVoice(buffer, SAMPLE_RATE);
//
//            // WebRTC VADë¡œ ì‚¬ëŒì´ ë§í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ë˜ëŠ”ì§€ ê²€ì‚¬
//            boolean isSpeech = vad.isSpeech(buffer, SAMPLE_RATE);
//
//            long now = System.currentTimeMillis();
//            Log.e("limdb", ""+(int)db + " freq:"+isVoiceFreq +" -speech:"+isSpeech);
//
//            // ìœ„ 3ê°€ì§€ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ë©´ ë§ì†Œë¦¬ë¡œ íŒë‹¨
//            if (db > -30 && isVoiceFreq && isSpeech) {
//                Log.e("limdb", ""+(int)db + " freq:"+isVoiceFreq +" -10:"+isSpeech);
//                // ì²˜ìŒ ë§ì†Œë¦¬ê°€ ê°ì§€ë˜ë©´ ë…¹ìŒ ì‹œì‘
//                if (!isRecording) {
//                    isRecording = true;
//                    recordingStartTime = now;
//                    speechBuffer.reset();                          // ë²„í¼ ì´ˆê¸°í™”
//                    Log.i("SpeechRecorder", "â–¶ ë…¹ìŒ ì‹œì‘ë¨");
//                }
//                Log.e("limdb",""+(int) db);
//                try {
//                    // í˜„ì¬ í”„ë ˆì„ì„ speechBufferì— ì¶”ê°€ ì €ì¥
//                    speechBuffer.write(buffer);
//                    lastSpeechTime = now;  // ë§ˆì§€ë§‰ ë§ì†Œë¦¬ ì‹œê°„ ê°±ì‹ 
//                } catch (IOException e) {
//                    Log.e("SpeechRecorder", "ë²„í¼ ì“°ê¸° ì‹¤íŒ¨", e);
//                }
//            } else if (isRecording) {
//                long duration = now - recordingStartTime; // ë…¹ìŒ ì‹œì‘ìœ¼ë¡œ ë¶€í„° 2ì´ˆê°€ ê²½ê³¼í–ˆëŠ”ì§€
//                long detectiedTime = now - lastSpeechTime;
//                // ğŸ“Œ ì¡°ê±´ 1: ë¬´ìŒì´ 2ì´ˆ ì´ìƒ ì§€ì†ë˜ê³ , ì´ ë…¹ìŒ ê¸¸ì´ê°€ 2ì´ˆ ì´ìƒì´ë©´ ì €ì¥
//
//                if ((detectiedTime > SILENCE_TIMEOUT_MS) && duration >= MIN_RECORDING_MS) {
//                    byte[] speech = speechBuffer.toByteArray();
//                    Log.i("limdb", ""+(int)db + " freq:"+isVoiceFreq +" -10:"+isSpeech);
//
//                    // í˜„ì¬ ë…¹ìŒ êµ¬ê°„ ê¸¸ì´ (ms ê¸°ì¤€)
//                    long recordedMs = duration;
//
//                    // 5ì´ˆë³´ë‹¤ ë¶€ì¡±í•œ ê²½ìš° â†’ preBufferì—ì„œ ë¶€ì¡±í•œ ì‹œê°„ë§Œí¼ ì•ì— ì¶”ê°€
//                    if (recordedMs < MAX_RECORDING_MS) {
//                        long neededMs = MAX_RECORDING_MS - recordedMs;
//
//                        int frameBytes = 160 * 2; // 10msë‹¹ 320byte
//                        int neededFrames = (int)(neededMs / 10); // 10ms ë‹¨ìœ„ í”„ë ˆì„ ìˆ˜
//                        int preBytes = neededFrames * frameBytes;
//
//                        byte[] prefix = preBuffer.getLastNBytes(preBytes); // ë¶€ì¡±í•œ ì•ë¶€ë¶„ë§Œí¼ í”„ë¦¬ë²„í¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°
//
//                        ByteArrayOutputStream finalAudio = new ByteArrayOutputStream();
//                        try {
//                            finalAudio.write(prefix);
//                            finalAudio.write(speech);
//                        } catch (IOException e) {
//                            Log.e("finalAudio", "ë²„í¼ ì“°ê¸° ì‹¤íŒ¨", e);
//                        }
//                        saveWavFile(finalAudio.toByteArray());
//                        Log.i("SpeechRecorder", "â–  ë…¹ìŒ ì¢…ë£Œë¨, duration = " + duration + "ms");
//                    } else {
//                        // í”„ë¦¬ë²„í¼ ë¶™ì¼ í•„ìš” ì—†ìŒ
//                        saveWavFile(speech);
//                        Log.i("SpeechRecorder", "â–  ë…¹ìŒ ì¢…ë£Œë¨, duration = " + duration + "ms");
//                    }
//
//                isRecording = false;
//                } else if ((detectiedTime > SILENCE_TIMEOUT_MS) && duration < MIN_RECORDING_MS){
//
//
//                    Log.i("limdb", ""+(int)db + " freq:"+isVoiceFreq +" -10:"+isSpeech);
//
//
//                    isRecording = false;
//                    Log.e("SpeechRecorder", "â–  ë…¹ìŒ ì·¨ì†Œë¨, duration = " + duration + "ms");
//                    // ğŸ“Œ ì¡°ê±´ 2: 5ì´ˆë¥¼ ì´ˆê³¼í•´ë„ ìë™ìœ¼ë¡œ ì €ì¥ ë° ì¢…ë£Œ
//                } else if(duration >= MAX_RECORDING_MS) {
//                    saveWavFile(speechBuffer.toByteArray());
////                    runWhisper();
//                    isRecording = false;
//                    Log.e("SpeechRecorder", "â–  ë…¹ìŒ ì¢…ë£Œë¨, duration = " + duration + "ms");
//                }
//            }
//        }
//
//
//        recorder.stop();
//        recorder.release();
//    }


    private void saveWavFile(byte[] pcm) {
        try {
            File dir = new File(getExternalFilesDir(null), "vad_speech");
            if (!dir.exists()) dir.mkdirs();

//            File file = new File(dir, "utterance_" + System.currentTimeMillis() + ".wav");
            String timeStamp = new SimpleDateFormat("yyyy-MM-dd_HH-mm-ss").format(new Date());
            File file = new File(dir, "utterance_" + timeStamp + ".wav");
            byte[] wav = Utils.pcmToWav(pcm, SAMPLE_RATE);
            FileOutputStream fos = new FileOutputStream(file);
            fos.write(wav);
            fos.close();

            Log.d("VAD", "Saved: " + file.getAbsolutePath());
        } catch (Exception e) {
            Log.e("VAD", "íŒŒì¼ ì €ì¥ ì‹¤íŒ¨", e);
        }
    }

    @Override
    public void onDestroy() {
        isRunning = false;
        super.onDestroy();
    }

    @Override
    public IBinder onBind(Intent intent) {
        return null;
    }

    // ë³´ì¡° í•¨ìˆ˜
    private byte[] mergeFrames(List<byte[]> frames) {
        ByteArrayOutputStream out = new ByteArrayOutputStream();
        for (byte[] f : frames) {
            try {
                out.write(f);
            } catch (IOException e) {
                Log.e("Recorder", "merge ì‹¤íŒ¨", e);
            }
        }
        return out.toByteArray();
    }

    // ë³´ì¡° í•¨ìˆ˜
    private void finalizeAndSave(CircularAudioBuffer preBuffer, ByteArrayOutputStream speechBuffer,
                                 long duration, long maxMs) {
        byte[] speech = speechBuffer.toByteArray();

        long missingMs = maxMs - duration;
        int frameBytes = 160 * 2;
        int neededFrames = (int)(missingMs / 10);
        int preBytes = neededFrames * frameBytes;

        byte[] prefix = preBuffer.getLastNBytes(preBytes);

        try {
            ByteArrayOutputStream finalAudio = new ByteArrayOutputStream();
            finalAudio.write(prefix);
            finalAudio.write(speech);
            saveWavFile(finalAudio.toByteArray());
            Log.i("Recorder", "â–  ë…¹ìŒ ì™„ë£Œ. ì €ì¥ë¨");
        } catch (IOException e) {
            Log.e("Recorder", "ì €ì¥ ì‹¤íŒ¨", e);
        }
    }

}
