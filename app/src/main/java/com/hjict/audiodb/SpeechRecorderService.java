package com.hjict.audiodb;

import android.app.Notification;
import android.app.NotificationChannel;
import android.app.NotificationManager;
import android.app.Service;
import android.content.Intent;
import android.media.AudioFormat;
import android.media.AudioRecord;
import android.media.MediaRecorder;
import android.os.Build;
import android.os.IBinder;
import android.util.Log;

import androidx.core.app.NotificationCompat;

import com.hjict.audiodb.Utils;

import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;

public class SpeechRecorderService extends Service {
    private AudioRecord recorder;
    private boolean isRunning = false;
    private VadWrapper vad;
    private ByteArrayOutputStream speechBuffer;

    private CircularAudioBuffer preBuffer;
    private long lastSpeechTime = 0;
    private static final int SAMPLE_RATE = 16000;
    private static final int FRAME_SIZE = 160; // 10ms @ 16kHz
    private static final int SILENCE_TIMEOUT_MS = 2000;

    private boolean isRecording = false;
    private int silenceFrameCount = 0;
    private int speechFrameCount = 0;
    private final int MIN_SPEECH_FRAMES = 100;  // ì˜ˆ: 100 frames = 1ì´ˆ (10ms * 100)
    private final int MAX_SILENCE_FRAMES = 100; // ì˜ˆ: 200 frames = 2ì´ˆ (10ms * 200)

    @Override
    public int onStartCommand(Intent intent, int flags, int startId) {
        // Foreground ì„œë¹„ìŠ¤ìš© ì•Œë¦¼ ìƒì„±
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
            NotificationChannel channel = new NotificationChannel(
                    "speech_channel",
                    "Speech Recorder",
                    NotificationManager.IMPORTANCE_LOW
            );
            NotificationManager manager = getSystemService(NotificationManager.class);
            if (manager != null) {
                manager.createNotificationChannel(channel);
            }
        }

        Notification notification = new NotificationCompat.Builder(this, "speech_channel")
                .setContentTitle("ìŒì„± ê°ì§€ ì¤‘")
                .setContentText("ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤...")
                .setSmallIcon(R.drawable.ic_launcher_background)  // ì ì ˆí•œ ì•„ì´ì½˜ ì„¤ì • í•„ìš”
                .build();

        startForeground(1, notification); // í•„ìˆ˜ í˜¸ì¶œ

        // 3ì´ˆ = 300 í”„ë ˆì„ (10ms), í”„ë ˆì„ë‹¹ 160 samples * 2 bytes = 320 bytes
        int frameSize = FRAME_SIZE * 2;
        preBuffer = new CircularAudioBuffer(300, frameSize); // 300ê°œ í”„ë ˆì„ ë³´ê´€ìš©

        // ë‚˜ë¨¸ì§€ ë¡œì§
        vad = new VadWrapper();
        vad.init(3); //  ë¯¼ê°
        new Thread(this::recordLoop).start();
        return START_STICKY;
    }

    private void recordLoop() {
        int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE,
                AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT);

        recorder = new AudioRecord(MediaRecorder.AudioSource.MIC,
                SAMPLE_RATE, AudioFormat.CHANNEL_IN_MONO,
                AudioFormat.ENCODING_PCM_16BIT, bufferSize);

        recorder.startRecording();
        isRunning = true;

        speechBuffer = new ByteArrayOutputStream();
        byte[] buffer = new byte[FRAME_SIZE * 2];

// ì„¤ì •ê°’: ìµœì†Œ/ìµœëŒ€ ë…¹ìŒ ì‹œê°„, ë¬´ìŒ ì§€ì† ì‹œê°„
        final long MAX_RECORDING_MS = 5000;       // ìµœëŒ€ 5ì´ˆ ë…¹ìŒ
        final long MIN_RECORDING_MS = 3000;       // ìµœì†Œ 2ì´ˆ ì´ìƒì¼ ë•Œë§Œ ì €ì¥ (2ì´ˆ + ë¬´ìŒ ê°ì§€ 2ì´ˆ)
        final long SILENCE_TIMEOUT_MS = 2000;     // 2ì´ˆ ì´ìƒ ë¬´ìŒì´ë©´ ë§ì´ ëë‚¬ë‹¤ê³  íŒë‹¨

// íƒ€ì´ë¨¸ ì´ˆê¸°í™”
        long recordingStartTime = 0;              // ë…¹ìŒ ì‹œì‘ ì‹œê°„ ê¸°ë¡ìš©
        long lastSpeechTime = 0;                  // ë§ˆì§€ë§‰ìœ¼ë¡œ ë§ì†Œë¦¬ ê°ì§€ëœ ì‹œì 
        boolean isRecording = false;              // í˜„ì¬ ë…¹ìŒ ì¤‘ì¸ì§€ ì—¬ë¶€

        while (isRunning) {
            // AudioRecordë¡œ ì˜¤ë””ì˜¤ í”„ë ˆì„ ì½ê¸° (10ms ë‹¨ìœ„)
            int read = recorder.read(buffer, 0, buffer.length);
            if (read != buffer.length) continue;  // ì½ê¸° ì‹¤íŒ¨ ë˜ëŠ” ë¶ˆì™„ì „í•œ í”„ë ˆì„ì€ ê±´ë„ˆëœ€

            // í”„ë¦¬ë²„í¼ì— í•­ìƒ ìŒ“ê¸° (10ms ë‹¨ìœ„ í”„ë ˆì„)
            preBuffer.addChunk(buffer);

            // í˜„ì¬ í”„ë ˆì„ì˜ ë°ì‹œë²¨ ê³„ì‚°
            double db = Utils.calculateDb(buffer, read);

            // í˜„ì¬ í”„ë ˆì„ì˜ ì£¼íŒŒìˆ˜ê°€ ì‚¬ëŒ ëª©ì†Œë¦¬ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ”ì§€ ê²€ì‚¬ (ex: 300~3000Hz)
            boolean isVoiceFreq = FftUtils.isHumanVoice(buffer, SAMPLE_RATE);

            // WebRTC VADë¡œ ì‚¬ëŒì´ ë§í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ë˜ëŠ”ì§€ ê²€ì‚¬
            boolean isSpeech = vad.isSpeech(buffer, SAMPLE_RATE);

            long now = System.currentTimeMillis();

            // ìœ„ 3ê°€ì§€ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ë©´ ë§ì†Œë¦¬ë¡œ íŒë‹¨
            if (db > -30 && isVoiceFreq && isSpeech) {
                Log.e("limdb", ""+(int)db + " freq:"+isVoiceFreq +" -10:"+isSpeech);
                // ì²˜ìŒ ë§ì†Œë¦¬ê°€ ê°ì§€ë˜ë©´ ë…¹ìŒ ì‹œì‘
                if (!isRecording) {
                    isRecording = true;
                    recordingStartTime = now;
                    speechBuffer.reset();                          // ë²„í¼ ì´ˆê¸°í™”
                    Log.i("SpeechRecorder", "â–¶ ë…¹ìŒ ì‹œì‘ë¨");
                }
                Log.e("limdb",""+(int) db);
                try {
                    // í˜„ì¬ í”„ë ˆì„ì„ speechBufferì— ì¶”ê°€ ì €ì¥
                    speechBuffer.write(buffer);
                    lastSpeechTime = now;  // ë§ˆì§€ë§‰ ë§ì†Œë¦¬ ì‹œê°„ ê°±ì‹ 
                } catch (IOException e) {
                    Log.e("SpeechRecorder", "ë²„í¼ ì“°ê¸° ì‹¤íŒ¨", e);
                }
            } else if (isRecording) {
                long duration = now - recordingStartTime; // ë…¹ìŒ ì‹œì‘ìœ¼ë¡œ ë¶€í„° 2ì´ˆê°€ ê²½ê³¼í–ˆëŠ”ì§€
                long detectiedTime = now - lastSpeechTime;
                // ğŸ“Œ ì¡°ê±´ 1: ë¬´ìŒì´ 2ì´ˆ ì´ìƒ ì§€ì†ë˜ê³ , ì´ ë…¹ìŒ ê¸¸ì´ê°€ 2ì´ˆ ì´ìƒì´ë©´ ì €ì¥

                if ((detectiedTime > SILENCE_TIMEOUT_MS) && duration >= MIN_RECORDING_MS) {
                    byte[] speech = speechBuffer.toByteArray();
                    Log.i("limdb", ""+(int)db + " freq:"+isVoiceFreq +" -10:"+isSpeech);

                    // í˜„ì¬ ë…¹ìŒ êµ¬ê°„ ê¸¸ì´ (ms ê¸°ì¤€)
                    long recordedMs = duration;

                    // 5ì´ˆë³´ë‹¤ ë¶€ì¡±í•œ ê²½ìš° â†’ preBufferì—ì„œ ë¶€ì¡±í•œ ì‹œê°„ë§Œí¼ ì•ì— ì¶”ê°€
                    if (recordedMs < MAX_RECORDING_MS) {
                        long neededMs = MAX_RECORDING_MS - recordedMs;

                        int frameBytes = 160 * 2; // 10msë‹¹ 320byte
                        int neededFrames = (int)(neededMs / 10); // 10ms ë‹¨ìœ„ í”„ë ˆì„ ìˆ˜
                        int preBytes = neededFrames * frameBytes;

                        byte[] prefix = preBuffer.getLastNBytes(preBytes); // ë¶€ì¡±í•œ ì•ë¶€ë¶„ë§Œí¼ í”„ë¦¬ë²„í¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°

                        ByteArrayOutputStream finalAudio = new ByteArrayOutputStream();
                        try {
                            finalAudio.write(prefix);
                            finalAudio.write(speech);
                        } catch (IOException e) {
                            Log.e("finalAudio", "ë²„í¼ ì“°ê¸° ì‹¤íŒ¨", e);
                        }
                        saveWavFile(finalAudio.toByteArray());
                        Log.i("SpeechRecorder", "â–  ë…¹ìŒ ì¢…ë£Œë¨, duration = " + duration + "ms");
                    } else {
                        // í”„ë¦¬ë²„í¼ ë¶™ì¼ í•„ìš” ì—†ìŒ
                        saveWavFile(speech);
                        Log.i("SpeechRecorder", "â–  ë…¹ìŒ ì¢…ë£Œë¨, duration = " + duration + "ms");
                    }

                isRecording = false;
                } else if ((detectiedTime > SILENCE_TIMEOUT_MS) && duration < MIN_RECORDING_MS){


                    Log.i("limdb", ""+(int)db + " freq:"+isVoiceFreq +" -10:"+isSpeech);


                    isRecording = false;
                    Log.e("SpeechRecorder", "â–  ë…¹ìŒ ì·¨ì†Œë¨, duration = " + duration + "ms");
                    // ğŸ“Œ ì¡°ê±´ 2: 5ì´ˆë¥¼ ì´ˆê³¼í•´ë„ ìë™ìœ¼ë¡œ ì €ì¥ ë° ì¢…ë£Œ
                } else if(duration >= MAX_RECORDING_MS) {
                    saveWavFile(speechBuffer.toByteArray());
//                    runWhisper();
                    isRecording = false;
                    Log.e("SpeechRecorder", "â–  ë…¹ìŒ ì¢…ë£Œë¨, duration = " + duration + "ms");
                }
            }
        }


        recorder.stop();
        recorder.release();
    }


    private void saveWavFile(byte[] pcm) {
        try {
            File dir = new File(getExternalFilesDir(null), "vad_speech");
            if (!dir.exists()) dir.mkdirs();

            File file = new File(dir, "utterance_" + System.currentTimeMillis() + ".wav");

            byte[] wav = Utils.pcmToWav(pcm, SAMPLE_RATE);
            FileOutputStream fos = new FileOutputStream(file);
            fos.write(wav);
            fos.close();

            Log.d("VAD", "Saved: " + file.getAbsolutePath());
        } catch (Exception e) {
            Log.e("VAD", "íŒŒì¼ ì €ì¥ ì‹¤íŒ¨", e);
        }
    }

    @Override
    public void onDestroy() {
        isRunning = false;
        super.onDestroy();
    }

    @Override
    public IBinder onBind(Intent intent) {
        return null;
    }
}
